import{_ as i,M as p,p as r,q as u,R as a,t as n,N as s,V as e,a1 as o}from"./framework-bafc524a.js";const d={},h=a("h1",{id:"wsl2-中搭建深度学习环境",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#wsl2-中搭建深度学习环境","aria-hidden":"true"},"#"),n(" WSL2 中搭建深度学习环境")],-1),k={class:"table-of-contents"},b=o(`<h2 id="_1-为什么使用-docker" tabindex="-1"><a class="header-anchor" href="#_1-为什么使用-docker" aria-hidden="true">#</a> 1. 为什么使用 Docker</h2><p>WSL2 Docker 内执行速度大约为 Ubuntu 主机的 80%，带来了一些性能牺牲。但是 Docker 的优势远比这点损失来的多：</p><ul><li>随时启动和停止一个环境</li><li>环境与主机隔离，主机可以正在做别的事情</li><li>同时运行多个环境，并分配 GPU</li><li>随意切换 CUDA 版本</li><li>随时备份和恢复一个环境，可将镜像迁移到不同机器上运行</li></ul><h2 id="_2-如何使用" tabindex="-1"><a class="header-anchor" href="#_2-如何使用" aria-hidden="true">#</a> 2. 如何使用</h2><p>条件：</p><ul><li>主机是现代 CPU 且是 x86 架构，安装有现代的 NVIDIA 显卡</li><li>需要 Windows 10 以上并安装有 WSL2。如果不了解如何安装可参考网络</li><li>首先需要安装 Docker Desktop，这同时会安装 WSL2 的两个容器 <code>docker-desktop-data</code> 和 <code>docker-desktop</code></li></ul><p>现在我们在主机查看 NVIDIA 显卡信息：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>nvidia-smi
</code></pre></div><p>得到 CUDA 版本，这个版本是你可以安装 CUDA 的最高版本，CUDA 是向下兼容的，因此可以使用比这更小的版本。</p>`,9),m={class:"hint-container info"},g=a("p",{class:"hint-container-title"},"升级显卡驱动",-1),v={href:"https://pytorch.org/blog/deprecation-cuda-python-support/",target:"_blank",rel:"noopener noreferrer"},f=o(`<p>其次：</p><ul><li><strong>不需要</strong> 在 Windows 上安装 CUDA 驱动</li><li><strong>不需要</strong> 在 Windows 上安装 cuDNN 组件</li><li><strong>不需要</strong> 在 WSL2 内安装显卡驱动或其他</li><li><strong>不需要</strong> 在容器内安装 CUDA 或其他</li></ul><p>这就是全部了，如果上述条件都满足就可以使用 PyTorch、TensorFlow 或任何你需要的环境继续了？</p><p>这是因为 WSL2 内核支持的 Docker 已经支持 <code>--gpus</code> 了（Docker 版本大于 19.03 即可），再也不需要 <code>nvidia-docker2</code> 来工作了。</p><h2 id="_3-安装-cuda-容器" tabindex="-1"><a class="header-anchor" href="#_3-安装-cuda-容器" aria-hidden="true">#</a> 3. 安装 CUDA 容器</h2><p>拉取 CUDA 11.6 Ubuntu 20.04 镜像（也可以直接拉取 PyTorch 镜像）：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">docker</span> pull nvidia/cuda:11.6.0-base-ubuntu20.04
</code></pre></div><p>创建容器，可指定参数：</p><ul><li>如果需要读外部数据请挂载目录或磁盘，如 <code>-v /mnt/d/docker_shared:/shared_data</code>（WSL2 内的磁盘路径为 <code>/mnt/c</code>、<code>/mnt/d</code>，对应 C、D 盘）</li><li>如果需要使用 Jupyter Notebook 请映射端口，如 <code>-p 8888:8888</code></li><li>如果机器有多个显卡，可以指定其序号 <code>--gpus 1,3</code>，一块 GPU 只能分配到一个正在运行的容器内</li></ul><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">docker</span> run <span class="token parameter variable">-itd</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--gpus</span> all <span class="token punctuation">\\</span>
    <span class="token parameter variable">--name</span> ub-cu11.6 <span class="token punctuation">\\</span>
    nvidia/cuda:11.6.0-base-ubuntu20.04 /bin/bash
</code></pre></div><p>创建一个更复杂的容器：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">docker</span> run <span class="token parameter variable">-itd</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">-v</span> /mnt/d/docker_shared:/shared_data <span class="token punctuation">\\</span>
    <span class="token parameter variable">-p</span> <span class="token number">8888</span>:8888 <span class="token punctuation">\\</span>
    <span class="token parameter variable">--gpus</span> all <span class="token punctuation">\\</span>
    <span class="token parameter variable">--name</span> ub-cu11.6 <span class="token punctuation">\\</span>
    nvidia/cuda:11.6.0-base-ubuntu20.04 /bin/bash
</code></pre></div><p>进入容器：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">docker</span> <span class="token builtin class-name">exec</span> <span class="token parameter variable">-it</span> ub-cu11.6 /bin/bash
</code></pre></div><p>现在和 Linux 系统一致了。</p><h2 id="_4-在容器内安装深度学习环境" tabindex="-1"><a class="header-anchor" href="#_4-在容器内安装深度学习环境" aria-hidden="true">#</a> 4. 在容器内安装深度学习环境</h2><p>更新镜像源：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">mv</span> /etc/apt/sources.list /etc/apt/sources.list-bak
<span class="token builtin class-name">echo</span> <span class="token string">&#39;deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse&#39;</span> <span class="token operator">&gt;</span> /etc/apt/sources.list
</code></pre></div><p>配置镜像后，下列操作基本为满速，十几分钟即可安装完成全部依赖。</p><p>安装工具：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">apt</span> update
<span class="token function">apt</span> upgrade <span class="token parameter variable">-y</span>
<span class="token function">apt</span> <span class="token function">install</span> <span class="token function">sudo</span> <span class="token function">vim</span> <span class="token function">wget</span> <span class="token function">curl</span> <span class="token function">git</span> <span class="token function">zip</span> <span class="token function">unzip</span> <span class="token function">tar</span> <span class="token parameter variable">-y</span>

<span class="token function">apt</span> <span class="token function">install</span> python3-pip
</code></pre></div><p>（可选）添加用户，并将用户可执行文件加入 PATH：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">useradd</span> <span class="token parameter variable">-r</span> <span class="token parameter variable">-m</span> <span class="token parameter variable">-s</span> /bin/bash admin
<span class="token comment"># 如果提示输入密码则输入密码</span>
<span class="token comment"># 如果没有提示则使用下面的命令修改密码</span>
<span class="token function">passwd</span> admin

<span class="token function">su</span> admin
<span class="token builtin class-name">cd</span>
<span class="token builtin class-name">echo</span> <span class="token string">&#39;export PATH=&quot;/home/admin/.local/bin:$PATH&quot;&#39;</span> <span class="token operator">&gt;</span> ~/.bashrc
<span class="token builtin class-name">source</span> ~/.bashrc
</code></pre></div><p>安装 Python 环境和常见依赖：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>python3 <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">-i</span> https://pypi.tuna.tsinghua.edu.cn/simple <span class="token parameter variable">--upgrade</span> pip

<span class="token comment"># 配置负载均衡的 PyPI 镜像，可快速选择较快的镜像源</span>
pip3 config <span class="token builtin class-name">set</span> global.extra-index-url <span class="token string">&quot;https://pypi.tuna.tsinghua.edu.cn/simple/ https://mirrors.aliyun.com/pypi/simple/ https://repo.huaweicloud.com/repository/pypi/simple/ https://mirrors.bfsu.edu.cn/pypi/web/simple/&quot;</span>
pip3 <span class="token function">install</span> opencv-python-headless
</code></pre></div><p>安装 PyTorch：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>pip3 <span class="token function">install</span> torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116
</code></pre></div><p>（可选）安装 YOLOv8 环境：</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code>pip3 <span class="token function">install</span> ultralytics
pip3 uninstall opencv-python
pip3 uninstall opencv-python-headless
pip3 <span class="token function">install</span> opencv-python-headless
</code></pre></div>`,29);function _(y,x){const c=p("RouterLink"),t=p("router-link"),l=p("ExternalLinkIcon");return r(),u("div",null,[h,a("p",null,[n("在 "),s(c,{to:"/docker/projects/deeplearning-env.html"},{default:e(()=>[n("Docker 搭建深度学习环境")]),_:1}),n(" 一文中，我们使用 Ubuntu 搭建了 Docker 下的深度学习环境。而 WSL2 同样也提供了完整的 CUDA 支持，我们可以在 Windows 下享受 Linux 环境下的优势。")]),a("nav",k,[a("ul",null,[a("li",null,[s(t,{to:"#_1-为什么使用-docker"},{default:e(()=>[n("1. 为什么使用 Docker")]),_:1})]),a("li",null,[s(t,{to:"#_2-如何使用"},{default:e(()=>[n("2. 如何使用")]),_:1})]),a("li",null,[s(t,{to:"#_3-安装-cuda-容器"},{default:e(()=>[n("3. 安装 CUDA 容器")]),_:1})]),a("li",null,[s(t,{to:"#_4-在容器内安装深度学习环境"},{default:e(()=>[n("4. 在容器内安装深度学习环境")]),_:1})])])]),b,a("div",m,[g,a("p",null,[n("如果你的 CUDA 版本小于 11.6 就建议升级显卡驱动了，PyTorch 即将取消 Python 3.7 和 CUDA 11.6 的支持（自 2023/2/1 开始，见 "),a("a",v,[n("官方博客"),s(l)]),n("），显卡驱动安装最新版通常不会出问题。")])]),f])}const U=i(d,[["render",_],["__file","deeplearning-env.html.vue"]]);export{U as default};
